
# My Personal Note:
These lists come from my Chrome Bookmark. After using a browser (not gonna tell you what's that:) ), moving these entries into a github is more convenient in term of accessibility reasons. 

I will start migrating my other lists here, soon. So, these list are still in progress to add/remove some more. 

## Deep Learning Related References:
- Deep Learning
    - Architectures:
        - Mainly in the field of Computer Vision. There are 10 types of architectures and each of those has original paper sources and codes.
         https://www.analyticsvidhya.com/blog/2017/08/10-advanced-deep-learning-architectures-data-scientists
        - Signal processing and Time series analysis.
        https://medium.com/alexrachnog/deep-learning-the-final-frontier-for-signal-processing-and-time-series-analysis-734307167ad6
        - GluonCV: Deep learning toolkit for computer vision:
        https://medium.com/apache-mxnet/gluoncv-deep-learning-toolkit-for-computer-vision-9218a907e8da
    	- Online class:
        	- Practical introduction to deep learning, theoretical aspects, and the implementations. Recomended to those who have plenty free time.
        https://courses.d2l.ai/berkeley-stat-157/syllabus.html
    - Backpropagation:
    	- Step by step:
        	- Example By Matt Mazur: explaining the basic work by using example, a Python script is also available in Github repo.
        https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/
        	- If you want to create your own Neural Network from scratch, likely suitable for those who will do exam and write everything from on a paper. Github repo is available.
        https://medium.com/14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c
    	- Optimization:
        	- Loss Evaluation, Softmax, and Cross Entropy loss. Complete source code is available in Github.
        https://deepnotes.io/softmax-crossentropy
        	- Softmax/Cross Entropy on output layer. This is recomended for those who are trying to get a deeper understanding on Backpropagation Optimization:
        https://stats.stackexchange.com/questions/235528/backpropagation-with-softmax-cross-entropy
        	- Plenty of discussion, mainly about Gradient Descent explanation.
        http://mccormickml.com/2014/03/04/gradient-descent-derivation/
        	- Basic explanation of Receiver Operating Characteristic (ROC). It would be good if you already have a good gars the concept of Confusion Matrix.
        https://medium.com/greyatom/lets-learn-about-auc-roc-curve-4a94b4d88152
    	- Implementation:
        	- The used of Backpropagation in the feed-fordward neural network from scratch with Python.
        https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/
        	- Multilayered perceptron from scratch:
        https://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-scratch.html#
	* Discriminant Analysis (DA)
    	- A Theorethical aspect of Fisher's Exact test from Wikipedia.
    https://en.wikipedia.org/wiki/Fisher%27s_exact_test
    	- Robust Fisher's Linear DA using sonar and ionosphere datasets written in Python.
    https://github.com/liuchen11/RobustFisherLDA
    	- Fisher's Linear DA from scratch in Python using Boston Housing and The Digits datasets. Github code is provided.
    http://goelhardik.github.io/2016/10/04/fishers-lda/
    	- A very rigorous of Principal Component Analysis and Linear DA using Iris Dataset.
    http://sebastianraschka.com/Articles/2014_python_lda.html
    	- The 'How To' comparison of PCA and Linear DA using scikit-learn from stackoverflow.com.
    https://stackoverflow.com/questions/31107945/how-to-perform-prediction-with-lda-linear-discriminant-in-scikit-learn
    	- Data compression using Dimensionality Reduction of Linear DA with scikit-learn. Source code is available on Github.
    https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Data_Compresssion_via_Dimensionality_Reduction_2_Linear_Discriminant_Analysis.php
    	- A Python Notebook based on the famous Iris dataset based on its original article in 1936.
    https://github.com/danilobellini/scientific-literature
    
