
# My Note:
These lists come from my Chrome Bookmark. After using a browser (not going to tell you what’s that:) ), moving these entries into a GitHub is more convenient in term of accessibility reasons.

I will start migrating my other lists here, soon. So, these lists are still in progress to add/remove some more.

## Machine Learning Related References:
- ### Deep Learning
    * #### Architectures:
        - Mainly in the field of Computer Vision. There are ten types of architectures, and each of those has original paper sources and codes  [URL](https://www.analyticsvidhya.com/blog/2017/08/10-advanced-deep-learning-architectures-data-scientists "URL").
        - Signal processing and Time series analysis [URL](https://medium.com/alexrachnog/deep-learning-the-final-frontier-for-signal-processing-and-time-series-analysis-734307167ad6 "URL").
        - GluonCV: Deep learning toolkit for computer vision [URL](https://medium.com/apache-mxnet/gluoncv-deep-learning-toolkit-for-computer-vision-9218a907e8da "URL").
    * #### Online class:
        - A practical introduction to deep learning, theoretical aspects, and implementations. Recommended to those who have plenty of free time [URL](https://courses.d2l.ai/berkeley-stat-157/syllabus.html "URL").
* ### Backpropagation:
    * #### Step by step:
        - Example By Matt Mazur: explaining how Backpropagation works along with its examples, a Python script is also available in Github repo [URL](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ "URL").
        - If you want to create your own Neural Network from scratch, likely suitable for those who will do an exam and are planning to make a paper sketch. Github repo is available [URL](https://medium.com/14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c "URL").
    * #### Optimization:
        - Loss Evaluation, Softmax, and Cross-Entropy loss. The complete source code is available in Github [URL](https://deepnotes.io/softmax-crossentropy "URL").
        - Softmax/Cross-Entropy on the output layer. This tutorial is recommended for those who are trying to get a deeper understanding on Backpropagation Optimization [URL](https://stats.stackexchange.com/questions/235528/backpropagation-with-softmax-cross-entropy "URL").
        - A discussion mainly about the interesting Gradient Descent [URL](http://mccormickml.com/2014/03/04/gradient-descent-derivation/ "URL").
        - Basic explanation of Receiver Operating Characteristic (ROC). It would be better if you already have a good grasp of the Confusion Matrix concept [URL](https://medium.com/greyatom/lets-learn-about-auc-roc-curve-4a94b4d88152 "URL").
    * #### Implementation:
        - The implementation of Backpropagation into the feed-forward neural network from scratch with Python [URL](https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/ "URL").
        - Multilayered perceptron from scratch [URL](https://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-scratch.html "URL")
* ### Discriminant Analysis (DA)
    * A Theoretical aspect of Fisher’s Exact test from Wikipedia [URL](https://en.wikipedia.org/wiki/Fisher%27s_exact_test "URL").
    * Robust Fisher’s Linear DA using sonar and ionosphere datasets written in Python [URL](https://github.com/liuchen11/RobustFisherLDA "URL").
    * Fisher's Linear DA from scratch in Python using Boston Housing and The Digits datasets. Github code is provided [URL](http://goelhardik.github.io/2016/10/04/fishers-lda/ "URL").
    * A very rigorous explanation of Principal Component Analysis and Linear DA using Iris Dataset [URL](http://sebastianraschka.com/Articles/2014_python_lda.html "URL").
    * The ‘How To' of PCA and Linear DA using scikit-learn from stackoverflow.com [URL](https://stackoverflow.com/questions/31107945/how-to-perform-prediction-with-lda-linear-discriminant-in-scikit-learn "URL").
    * Data compression using Dimensionality Reduction of Linear DA with scikit-learn. The source code is available on Github [URL](https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Data_Compresssion_via_Dimensionality_Reduction_2_Linear_Discriminant_Analysis.php "URL").
    * A Python Notebook with the well known Iris dataset based on its original  article published in 1936 [URL](https://github.com/danilobellini/scientific-literature "URL").
